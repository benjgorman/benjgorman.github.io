---
layout: publication
category: 'Short Paper'
title: "Reducing viseme confusion in speech reading"
authors: Benjamin M. Gorman
venue: "SIGACCESS"
year-published: 2016
link: "https://dl.acm.org/doi/10.1145/2661334.2661410"
abstract: Although our sense of hearing, smell, and vision allow us to perceive things at a distance, the detection of many day-to-day events relies exclusively on our hearing. For example, finding a ringing phone lost in a sofa, hearing a child cry in another room, and use of a car alarm to locate a vehicle in a car park. However, individuals with total or partial hearing loss have difficulty detecting the audible signals in these situations. We have developed VisAural, a system that converts audible signals into visual cues. Using an array of head-mounted microphones, VisAural detects the direction of a sound, and places LEDs at the periphery of the user's visual field to guide them to the source of the sound. We tested VisAural with nine people with hearing impairments and found that this approach holds great promise but needs to be made more responsive before it can be truly helpful.
---
layout: publication
category: 'Short Paper'
title: "Reducing viseme confusion in speech-reading test test"
authors: Benjamin M. Gorman
year-published: 2016
link: "https://dl.acm.org/doi/10.1145/2904092.2904100"
venue: "Test"
abstract: "Speech-reading is an invaluable technique for people with hearing loss or those in adverse listening conditions (e.g., in a noisy restaurant, near children playing loudly). However, speech-reading is often difficult because identical mouth shapes (visemes) can produce several speech sounds (phonemes) there is a one-to-many mapping from visemes to phonemes. This decreases comprehension, causing confusion and frustration during conversation. My doctoral research aims to design and evaluate a visualisation technique that displays textual representations of a speaker's phonemes to a speech-reader. By combining my visualisation with their pre-existing speech-reading ability, speech-readers should be able to disambiguate confusing viseme-to-phoneme mappings without shifting their focus from the speaker's face. This will result in an improved level of comprehension, supporting natural conversation."
