<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <title>Xr Subtitle Suite | Benjamin Gorman</title>
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="shortcut icon" type="image/png" href="/favicon.png">
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-169272909-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-169272909-1');
</script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Xr Subtitle Suite | Benjamin Gorman</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Xr Subtitle Suite" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A research collaboration between Bournemouth University, University of Dundee, and ITV, supported by XR Network+, resulting in three working prototype tools that repurpose subtitle data for Virtual Production workflows." />
<meta property="og:description" content="A research collaboration between Bournemouth University, University of Dundee, and ITV, supported by XR Network+, resulting in three working prototype tools that repurpose subtitle data for Virtual Production workflows." />
<link rel="canonical" href="http://localhost:4000/projects/xr-subtitle-suite" />
<meta property="og:url" content="http://localhost:4000/projects/xr-subtitle-suite" />
<meta property="og:site_name" content="Benjamin Gorman" />
<meta property="og:image" content="http://localhost:4000/assets/images/project_images/xr-network-thumb.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-24T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:image" content="http://localhost:4000/assets/images/project_images/xr-network-thumb.png" />
<meta property="twitter:title" content="Xr Subtitle Suite" />
<meta name="twitter:site" content="@benjgorman" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-06-24T00:00:00+01:00","datePublished":"2025-06-24T00:00:00+01:00","description":"A research collaboration between Bournemouth University, University of Dundee, and ITV, supported by XR Network+, resulting in three working prototype tools that repurpose subtitle data for Virtual Production workflows.","headline":"Xr Subtitle Suite","image":"http://localhost:4000/assets/images/project_images/xr-network-thumb.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/projects/xr-subtitle-suite"},"url":"http://localhost:4000/projects/xr-subtitle-suite"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    
<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400italic,700|Kreon:400,700' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/responsive-nav.css">
<script src="/responsive-nav.js"></script>

<script>
	/*! grunt-grunticon Stylesheet Loader - v2.1.6 | https://github.com/filamentgroup/grunticon | (c) 2015 Scott Jehl, Filament Group, Inc. | MIT license. */

	!function(){function e(e,n,t,o){"use strict";var r=window.document.createElement("link"),a=n||window.document.getElementsByTagName("script")[0],i=window.document.styleSheets;return r.rel="stylesheet",r.href=e,r.media="only x",o&&(r.onload=o),a.parentNode.insertBefore(r,a),r.onloadcssdefined=function(n){for(var t,o=0;o<i.length;o++)i[o].href&&i[o].href.indexOf(e)>-1&&(t=!0);t?n():setTimeout(function(){r.onloadcssdefined(n)})},r.onloadcssdefined(function(){r.media=t||"all"}),r}function n(e,n){e.onload=function(){e.onload=null,n&&n.call(e)},"isApplicationInstalled"in navigator&&"onloadcssdefined"in e&&e.onloadcssdefined(n)}!function(t){var o=function(r,a){"use strict";if(r&&3===r.length){var i=t.navigator,c=t.document,d=t.Image,s=!(!c.createElementNS||!c.createElementNS("http://www.w3.org/2000/svg","svg").createSVGRect||!c.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#Image","1.1")||t.opera&&-1===i.userAgent.indexOf("Chrome")||-1!==i.userAgent.indexOf("Series40")),l=new d;l.onerror=function(){o.method="png",o.href=r[2],e(r[2])},l.onload=function(){var t=1===l.width&&1===l.height,i=r[t&&s?0:t?1:2];t&&s?o.method="svg":t?o.method="datapng":o.method="png",o.href=i,n(e(i),a)},l.src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==",c.documentElement.className+=" grunticon"}};o.loadCSS=e,o.onloadCSS=n,t.grunticon=o}(this),function(e,n){"use strict";var t=n.document,o="grunticon:",r=function(e){if(t.attachEvent?"complete"===t.readyState:"loading"!==t.readyState)e();else{var n=!1;t.addEventListener("readystatechange",function(){n||(n=!0,e())},!1)}},a=function(e){return n.document.querySelector('link[href$="'+e+'"]')},i=function(e){var n,t,r,a,i,c,d={};if(n=e.sheet,!n)return d;t=n.cssRules?n.cssRules:n.rules;for(var s=0;s<t.length;s++)r=t[s].cssText,a=o+t[s].selectorText,i=r.split(");")[0].match(/US\-ASCII\,([^"']+)/),i&&i[1]&&(c=decodeURIComponent(i[1]),d[a]=c);return d},c=function(e){var n,r,a,i;a="data-grunticon-embed";for(var c in e){i=c.slice(o.length);try{n=t.querySelectorAll(i)}catch(d){continue}r=[];for(var s=0;s<n.length;s++)null!==n[s].getAttribute(a)&&r.push(n[s]);if(r.length)for(s=0;s<r.length;s++)r[s].innerHTML=e[c],r[s].style.backgroundImage="none",r[s].removeAttribute(a)}return r},d=function(n){"svg"===e.method&&r(function(){c(i(a(e.href))),"function"==typeof n&&n()})};e.embedIcons=c,e.getCSS=a,e.getIcons=i,e.ready=r,e.svgLoadedCallback=d,e.embedSVG=d}(grunticon,this)}();
	grunticon(["/grunt/output/icons.data.svg.css", "/grunt/output/icons.data.png.css", "/grunt/output/icons.fallback.css"], grunticon.svgLoadedCallback );
	</script>
	<noscript><link href="/grunt/output/icons.fallback.css" rel="stylesheet"></noscript>

<header class="header" role="banner">
	<div id="inner-header" class="wrap_nav">
    <nav class="nav-collapse">
      <ul>
        
        <li><a href="/" data-hover="Home">Home</a></li>
        
        <li><a href="/consultancy" data-hover="Consultancy">Consultancy</a></li>
        
        <li><a href="/projects" data-hover="Projects">Projects</a></li>
        
        <li><a href="/publications" data-hover="Publications">Publications</a></li>
        
        <li><a href="/about" data-hover="About">About</a></li>
        
      </ul>
    </nav>
    <div class="page-logos">
       <a href="\" rel="nofollow"><div id="logo_nav" class="icon-bg"><div class="invisible">Go to home</div></div></a>
       <a href="#"><div id="newtoggle" class="icon-open" style="width: 30px; height: 35px; background-size:100%;"><div class="invisible">Menu</div></div></a>
    </div>
		</div>
</header>

    <div id="content" class="container">
      <div id="inner-content" class="wrap cf">
          <div id="main" role="main">
            <article>
  <section class="entry-content wrap">
    <article class="container wrap">
      <header class="article-header">
      	<p class="post-date">2025</p>
        <h1 class="post-title">Xr Subtitle Suite</h1>
      </header>
      <hr>
      <section class="container wrap">
        <h2>Description</h2>
        <p>A research collaboration between Bournemouth University, University of Dundee, and ITV, supported by XR Network+, resulting in three working prototype tools that repurpose subtitle data for Virtual Production workflows.</p>
      </section>
      <hr>
      <section class="container wrap">

        <h1 id="xr-subtitle-suite--repurposing-subtitle-data-for-virtual-production">XR Subtitle Suite – Repurposing Subtitle Data for Virtual Production</h1>

<p><strong>Project partners:</strong> Bournemouth University, University of Dundee, ITV<br />
<strong>Funded by:</strong> XR Network+ (Prototyping, Impact &amp; Acceleration – Round 2)</p>

<p>This research project brought together Bournemouth University and the University of Dundee in collaboration with ITV to explore how subtitle data could be reconceptualised within Virtual Production (VP). Subtitles – typically viewed as an accessibility or translation asset – were reframed as a generative, structural, and editorial resource capable of shaping new forms of media interaction.</p>

<p>The six-month project was supported by XR Network+ and aimed not only to enhance an existing prototype, but to push further into the unexplored creative value of subtitle files. Rather than being static text layers, this project treated subtitles as <strong>narrative metadata</strong>, offering insight into character, tone, pacing, and scene structure. Through rapid iteration, collaboration with ITV, and iterative evaluation, the research produced a suite of three fully working tools.</p>

<hr />

<h2 id="why-subtitles">Why Subtitles?</h2>

<p>Subtitles are available for enormous volumes of broadcast media, yet their use is usually confined to linear display. This project asked a simple but transformative question:</p>

<p><strong>What if subtitles became an input for editing, automation, and creative transformation instead of just an output layer?</strong></p>

<p>By analysing dialogue structure, speaker turns, silence, pacing, sentiment, and contextual markers, subtitles can reveal:</p>

<ul>
  <li>who is speaking, how often, and with what emotional intent</li>
  <li>how scenes flow, break, accelerate, or centre around conflict</li>
  <li>where meaning is created through timing, rhythm, or contradiction</li>
  <li>opportunities for accessibility improvements, reduction, summarisation, and alternate viewing modes</li>
</ul>

<p>This shift in perspective opened up new workflows for VP teams, editors, researchers, and audience-facing experiences.</p>

<hr />

<h2 id="the-three-prototype-tools">The Three Prototype Tools</h2>

<p>Each tool works independently but draws from the same subtitle data foundation. Together, they form a toolkit for segmentation, transformation, and creative media interpretation.</p>

<h3 id="1-subtitle-based-media-segmentation">1. Subtitle-Based Media Segmentation</h3>

<p>A browser interface that allows users to divide and export media based on:</p>

<ul>
  <li><strong>Speaker</strong> — e.g. all of one character’s dialogue for training, analysis, or character-centred cuts</li>
  <li><strong>Chapters</strong> — using structural metadata to isolate scenes or narrative beats</li>
  <li><strong>Time-based ranges</strong> — rapidly extracting windows for review, summarisation, or short-form editing</li>
</ul>

<p>This makes it possible to generate themed edits, accessibility-first versions, or character-focused highlight reels in seconds, rather than manually.</p>

<h3 id="2-printedmedia--graphic-novel--print-style-output-generator">2. PrintedMedia – Graphic Novel &amp; Print-Style Output Generator</h3>

<p>This tool transforms video + subtitle data into <strong>visual print artefacts</strong>:</p>

<ul>
  <li>comic-style page layouts built from extracted video frames</li>
  <li>speech balloons generated directly from subtitle text</li>
  <li>automatic condensation of scenes into narrative summaries</li>
</ul>

<p>Designed not only for accessibility but for <strong>media literacy, education, and creative reinterpretation</strong>, it demonstrates how broadcast content can become visual storytelling material, teaching resource, or archival object.</p>

<h3 id="3-sentiment--tone-driven-stylised-output">3. Sentiment &amp; Tone-Driven Stylised Output</h3>

<p>A more experimental prototype that uses subtitle data to infer:</p>

<ul>
  <li>emotional tone (anger, tension, calm, humour)</li>
  <li>character relationships and dynamics</li>
  <li>pacing changes, escalation, conflict</li>
</ul>

<p>Visual output changes dynamically — applying colour, composition, or motion effects that reflect mood. This tool tests how data-led rendering might one day allow automated editorial stylisation, mood summaries, or emotion-led narrative versions of broadcast media.</p>

<hr />

<h2 id="evaluation--impact">Evaluation &amp; Impact</h2>

<p>All three tools were evaluated through participant interviews with industry professionals and educators. Key findings included:</p>

<ul>
  <li>intuitive interfaces with low learning curves</li>
  <li>valuable potential for editorial, archive, and VP workflow integration</li>
  <li>applications for education, accessibility, and short-form content creation</li>
</ul>

<p>Feedback directly shaped the final refinements, confirming future development value across industry and research contexts.</p>

<hr />

<h2 id="future-work">Future Work</h2>

<p>Building on these prototypes, future research with ITV will explore how <strong>structured media metadata — including subtitles, scripts, and audio descriptions — can drive automation, adaptive rendering, and enhanced engagement in Virtual Production workflows</strong>.</p>

<p>There is clear opportunity to develop:</p>

<ul>
  <li>adaptive editing pipelines</li>
  <li>real-time narrative visualisation</li>
  <li>archive search + retrieval tools</li>
  <li>accessibility-first content transformations</li>
</ul>

<hr />

<p>This project is one of four funded through the XR Network+ PIA initiative, awarding up to £10,000 for UK research exploring new ideas in Virtual Production. Work began in September 2024 and concluded with three publicly demonstrable prototypes.</p>

<p>Image credit: Benjamin Gorman.</p>


        

        
      </section>
  </section>
</article>

            </div>
          </div>
      </div>

    </body>
    <script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js" integrity="sha384-SlE991lGASHoBfWbelyBPLsUlwY1GwNDJo3jSJO04KZ33K2bwfV9YBauFfnzvynJ" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>


<footer class="footer" id="footer">
      <div class="container">
				<p class="text_center copyright">Find me elsewhere:</p>
				<ul class="social">
          <li><a title="You should follow me on Twitter" href="http://twitter.com/benjgorman"><div class="icon-twitter" data-grunticon-embed></div></a></li>
					<li><a title="Follow me on Instagram" href="http://instagram.com/benjgorman"><div class="icon-instagram" data-grunticon-embed></div></a></li>
					<li><a title="Follow me on Github" href="http://github.com/benjgorman"><div class="icon-github" data-grunticon-embed></div></a></li>
				</ul>
				<p class="source-org copyright">Copyright &copy; 2025 Benjamin Gorman. All rights reserved. </br> Designed by me probably sipping a cappuccino. Powered by <a href="https://jekyllrb.com/">Jekyll</a>.</p>
      </div>
</footer>

    <div class="push"></div>
    </div>
  <script>
  	var nav = responsiveNav(".nav-collapse");
  </script>
</html>
